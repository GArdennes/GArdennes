{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPnXlf8zwW6cTAbJhEwpPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GArdennes/GArdennes/blob/main/Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the drawback of Decision trees we consider an upgrade to decision trees called Random Forests. Decision trees easily overfit and with reach result have high variance in the results unless a seed is used. Although decision trees are superior to logical regression models in that they do not carry assumptions into processing the data. Logical regression models assume the data can be split into two exact categories which is not the case for all data. Random forests contain multiple trees."
      ],
      "metadata": {
        "id": "N9DG6PDUPxnJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAoHFPEGPrER"
      },
      "outputs": [],
      "source": [
        "#bootstrap sampling to create multiple datasets of same size and reduce overfitting\n",
        "#bagging (applying an ensemble classifier like Random forest) <- aggregating(applying classifier model) <- bootstrapping(resampling) <- orginal data\n",
        "#at the aggregating of the data we go through decorrelation of the decision tree classifer, \n",
        "#this means adding restrictions to the trees to introduce variances thus making the decision trees more random."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using Random Forest\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
        "df['target'] = cancer_data['target']\n",
        "\n",
        "X = df[cancer_data.feature_names].values\n",
        "y = df['target'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101) # random state affects the accuracy of the model, another suggestion was k-fold algorithm to ensure reliable vales\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"random forest accuracy:\", rf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "HaDn6h43at4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------BREAKAWAYOP-------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "60xuNbfDbLlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------BREAKAWAYCL-------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "QkgylCtRbSoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using Decision Trees\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
        "df['target'] = cancer_data['target']\n",
        "\n",
        "X = df[cancer_data.feature_names].values\n",
        "y = df['target'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "print(\"decision tree accuracy:\", dt.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "4FXpuTObbYF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#n_estimators (the number of trees)\n",
        "#max_features (the number of features to consider at each split)\n",
        "#rf = RandomForestClassifier(max_features=5) default\n",
        "#rf = RandomForestClassifier(n_estimators=15) default\n",
        "#Grid search to implement k-fold cross validation\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
        "df['target'] = cancer_data['target']\n",
        "\n",
        "X = df[cancer_data.feature_names].values\n",
        "y = df['target'].values\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 25, 50, 75, 100],\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 101) # random state affects the accuracy of the model,k-fold algorithm to ensure reliable vales\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "gs = GridSearchCV(rf, param_grid, scoring='f1', cv=5) #cv = 5 for 5 fold cross validation\n",
        "gs.fit(X_train, y_train)\n",
        "print(\"best params:\", gs.best_params_)\n",
        "print(\"random forest accuracy:\", gs.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "D6lvAnChcWlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature_importance helps us determine in what measure the features contribute to the target\n",
        "#the higher the number the greater the contribution\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
        "df['target'] = cancer_data['target']\n",
        "\n",
        "X = df[cancer_data.feature_names].values\n",
        "y = df['target'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=101)\n",
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "ft_imp = pd.Series(rf.feature_importances_, index=cancer_data.feature_names).sort_values(ascending=False)\n",
        "print(ft_imp.head(10))"
      ],
      "metadata": {
        "id": "nWTgECUBNVYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature selection enables us build relevant subsets of the data thus neglecting data noise\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
        "df['target'] = cancer_data['target']\n",
        "\n",
        "X = df[cancer_data.feature_names].values\n",
        "y = df['target'].values\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10, random_state=111)\n",
        "\n",
        "worst_cols = [col for col in df.columns if 'worst' in col]\n",
        "X_worst = df[worst_cols]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_worst, y, random_state=101)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"random forest accuracy:\",rf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "0KvhfO5iO882"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing Logistic Regression to Random Forests on a generated dataset"
      ],
      "metadata": {
        "id": "h7InWwhfRpCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "lr_scores = []\n",
        "rf_scores = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    lr = LogisticRegression(solver='lbfgs')\n",
        "    lr.fit(X_train, y_train)\n",
        "    lr_scores.append(lr.score(X_test, y_test))\n",
        "    rf = RandomForestClassifier(n_estimators=100)\n",
        "    rf.fit(X_train, y_train)\n",
        "    rf_scores.append(rf.score(X_test, y_test))\n",
        "print(\"LR accuracy:\", np.mean(lr_scores))\n",
        "print(\"RF accuracy:\", np.mean(rf_scores))"
      ],
      "metadata": {
        "id": "sdiQpx4IRofi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}